{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import re\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "from lxml.html import fromstring\n",
    "from collections import Counter\n",
    "from requests.packages.urllib3.util import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests import Session, exceptions\n",
    "import sys\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sys.path.append(\"/Users/rohanramesh/Documents/GitHub/Insight_writers/lib/\")\n",
    "from text_processing import ProcessArticle as pa\n",
    "import suggestions as s\n",
    "import difflib\n",
    "from scipy.stats import wilcoxon, sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "with open('/Users/rohanramesh/Documents/Insight/data_bball_writers/Attempt3_mr_scrape.pickle', 'rb') as handle:\n",
    "    scrapevar = pickle.load(handle)\n",
    "    \n",
    "# load writer df\n",
    "with open('/Users/rohanramesh/Documents/Insight/data_bball_writers/writer_df.pickle', 'rb') as handle:\n",
    "    writer_df = pickle.load(handle)\n",
    "    \n",
    "# load writer features\n",
    "writer_features = pd.read_pickle('/Users/rohanramesh/Documents/Insight/data_bball_writers/writer_features.pickle')\n",
    "\n",
    "# load podcasts\n",
    "top_podcasts = pd.read_pickle('/Users/rohanramesh/Documents/Insight/data_bball_writers/top50podcasts.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'writer_feature_db'\n",
    "# dbname = 'writer_db'\n",
    "username = 'rohanramesh' # change this to your username\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print(engine.url)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to load entire db into pandas\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM writer_feature;\n",
    "\"\"\"\n",
    "writer_feature_df = pd.read_sql_query(sql_query,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT AVG(\"n_words\") AS \"avg_n_words\",\n",
    "         AVG(\"neg_sent\") AS \"avg_neg_sent\",\n",
    "         AVG(\"neu_sent\") AS \"avg_neu_sent\",\n",
    "         AVG(\"pos_sent\") AS \"avg_pos_sent\",\n",
    "         AVG(\"neg_sent_var\") AS \"avg_neg_sent_var\",\n",
    "         AVG(\"neu_sent_var\") AS \"avg_neu_sent_var\",\n",
    "         AVG(\"pos_sent_var\") AS \"avg_pos_sent_var\",\n",
    "        AVG(\"n_sentences\") AS \"avg_n_sentences\",\n",
    "        AVG(\"n_wordspersentence\") AS \"avg_n_wordspersentence\",\n",
    "        AVG(\"n_wordspersent_variability\") AS \"avg_n_wordspersent_variability\",\n",
    "        AVG(\"wordlength\") AS \"avg_wordlength\",\n",
    "        AVG(\"wordlength_var\") AS \"avg_wordlength_var\",\n",
    "        AVG(\"wordlength_skew\") AS \"avg_wordlength_skew\",\n",
    "        \"author_list\"\n",
    "FROM writer_feature\n",
    "WHERE \"n_words\" > 100\n",
    "GROUP BY \"author_list\"\n",
    "HAVING COUNT(*) > 25 \n",
    "ORDER BY AVG(\"n_words\") DESC\n",
    "\"\"\"\n",
    "writer_feature_subsection = pd.read_sql_query(sql_query,con)\n",
    "writer_feature_subsection.head(10)\n",
    "writer_feature_subsection.replace([np.inf, -np.inf], np.nan)\n",
    "writer_feature_subsection = writer_feature_subsection.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_webnames = writer_feature_subsection['author_list']\n",
    "author_list = []\n",
    "for i in author_webnames:\n",
    "    idx = writer_df['website_name'] == i\n",
    "#     print(i)\n",
    "#     print(writer_df['Idea Text'][np.where(idx)[0]].tolist()[0])\n",
    "#     break\n",
    "    author_list.append(writer_df['Idea Text'][np.where(idx)[0]].tolist()[0])\n",
    "    \n",
    "# author_list[41] = 'Jason Concepcion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type something in search key\n",
    "# new_id = url_format.format('zach', 'lowe')\n",
    "# new_id = 'https://www.listennotes.com/search/?q=zach%20lowe'\n",
    "page = requests.get(url_format)\n",
    "curr_soup = BeautifulSoup(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_podcasts = {}\n",
    "# for curr_author in author_list:\n",
    "#     top_podcasts[curr_author] = []\n",
    "#     r = word_tokenize(curr_author)\n",
    "#     page_idx = 0\n",
    "#     while page_idx < 50:\n",
    "# #         url = (\"https://listennotes.p.mashape.com/api\"\n",
    "# #             \"/v1/search?offset={}&q={}+{}&sort_by_date=0&type=episode\".format(page_idx,r[0], r[1]))\n",
    "# #         response = requests.get(url,\n",
    "# #           headers={\n",
    "# #             \"X-Mashape-Key\": \"PUT IN KEY\",\n",
    "# #             \"Accept\": \"application/json\"\n",
    "# #           }\n",
    "# #         )\n",
    "#         a = response.content\n",
    "#         b = json.loads(a)\n",
    "#         top_podcasts[curr_author].append(b)\n",
    "#         page_idx += 10\n",
    "#         time.sleep(random.uniform(0.5,2))\n",
    "#         print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These code snippets use an open-source library. http://unirest.io/python\n",
    "response = requests.get(\"https://listennotes.p.mashape.com/api/v1/search?offset=0&q=zach+lowe&sort_by_date=0&type=episode\",\n",
    "  headers={\n",
    "    \"X-Mashape-Key\": \"KEYINEMAIL\",\n",
    "    \"Accept\": \"application/json\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ast.literal_eval(a))\n",
    "a = response.content\n",
    "b = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each podcast lets identify fields to search\n",
    "author_mentions = np.zeros([len(author_list), len(author_list)])\n",
    "for i in range(0,len(author_list)):\n",
    "    curr_author = author_list[i]\n",
    "    # curr_page = 0\n",
    "    for curr_page in range(0,4):\n",
    "    # curr_pod = 0\n",
    "        for curr_pod in range(0,np.min([9,len(top_podcasts[curr_author][curr_page]['results'])])):\n",
    "            curr_info = top_podcasts[curr_author][curr_page]['results'][curr_pod]\n",
    "            podcast_keys = curr_info.keys()\n",
    "            matches = []\n",
    "            for curr_key in podcast_keys:\n",
    "                for j in range(0,len(author_list)):\n",
    "                    curr_authorcomp = author_list[j]\n",
    "                    if curr_authorcomp == 'Jason Concepcion/netw3rk':\n",
    "                        curr_authorcomp = 'Jason Concepcion'\n",
    "                    search_terms = curr_authorcomp\n",
    "                    #     matches = []\n",
    "                    if isinstance(curr_info[curr_key], str):\n",
    "                #         print(curr_info[curr_key])\n",
    "                        last_name = word_tokenize(search_terms)[1]\n",
    "                #         print(last_name)\n",
    "                    #     for word in search_terms.split(\" \"):\n",
    "                    #         print(word)\n",
    "                        if last_name in curr_info[curr_key]:\n",
    "                            author_mentions[i,j] = 1\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_info\n",
    "# top_podcasts[curr_author][curr_page]\n",
    "# np.min([9,len(top_podcasts[curr_author][curr_page]['results'])])\n",
    "def match_author_names(writer_df, author):\n",
    "    wa = writer_df['website_name'].tolist()\n",
    "    al = writer_df['Idea Text'].tolist()\n",
    "    if author in wa:\n",
    "        return al[wa.index(author)]\n",
    "    elif author in al:\n",
    "        return wa[al.index(author)]\n",
    "    else:\n",
    "        print('improper author name')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(author_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'Zach Lowe'\n",
    "idx = np.where(author_mentions[author_list.index(r)])\n",
    "b = [author_list[i] for i in idx[0] if author_list[i] != r]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_sugg = s.give_author_suggestion_from_author(writer_features, 'zachlowe_nba')\n",
    "print(author_sugg['authors'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate each author and see how many times match in podcasts in either direction\n",
    "# for i in range(0,len(author_list)):\n",
    "website_author_names = writer_df['website_name'].tolist()\n",
    "matched_fraction = []\n",
    "nonmatch_fraction = []\n",
    "for ii in range(0,len(author_list)):\n",
    "# ii = 7\n",
    "    if np.sum(author_mentions[ii,:]) <= 1:\n",
    "        print(author_list[ii])\n",
    "        continue\n",
    "    curr_author = author_list[ii]\n",
    "    website_name = match_author_names(writer_df, curr_author)\n",
    "    author_sugg = s.give_author_suggestion_from_author(writer_features, website_name)\n",
    "    author_sugg_list = author_sugg['authors'].tolist()\n",
    "    matched_authors = author_sugg_list[0:6]\n",
    "#     print(matched_authors)\n",
    "    nonmatched_authors = [i for i in website_author_names if i not in matched_authors]\n",
    "    # to remove same author\n",
    "    matched_authors = matched_authors[1:]\n",
    "    # get n for matched authors\n",
    "    n_match = []\n",
    "    for i in matched_authors:\n",
    "        idx1 = author_list.index(curr_author)\n",
    "        idx2 = author_list.index(match_author_names(writer_df, i))\n",
    "        val = np.max([author_mentions[idx1,idx2], author_mentions[idx2,idx1]])\n",
    "        n_match.append(val)\n",
    "    matched_fraction.append(np.sum(n_match)/len(n_match))\n",
    "    n_nonmatch = []\n",
    "    for i in nonmatched_authors:\n",
    "        if match_author_names(writer_df, i) in author_list:\n",
    "            idx1 = author_list.index(curr_author)  \n",
    "            idx2 = author_list.index(match_author_names(writer_df, i))\n",
    "            val = np.max([author_mentions[idx1,idx2], author_mentions[idx2,idx1]])\n",
    "            n_nonmatch.append(val)\n",
    "    nonmatch_fraction.append(np.sum(n_nonmatch)/len(n_nonmatch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(nonmatch_fraction)\n",
    "plt.show()\n",
    "plt.hist(matched_fraction)\n",
    "plt.show()\n",
    "print(np.mean(matched_fraction))\n",
    "print(np.mean(nonmatch_fraction))\n",
    "# (np.mean(matched_fraction)-np.mean(nonmatch_fraction))/np.mean(matched_fraction)\n",
    "# print((np.mean(nonmatch_fraction)*100)/(np.mean(matched_fraction)*100-np.mean(nonmatch_fraction)*100))\n",
    "print(np.mean(matched_fraction)/np.mean(nonmatch_fraction))\n",
    "a,pval = wilcoxon(matched_fraction, nonmatch_fraction)\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.boxplot([matched_fraction, nonmatch_fraction])\n",
    "plt.bar(range(0,2),[np.mean(matched_fraction)*100, np.mean(nonmatch_fraction)*100], 0.75, \n",
    "        yerr=[sem(matched_fraction)*100, sem(nonmatch_fraction)*100], tick_label= ['Suggested', 'Not suggested'])\n",
    "plt.ylabel('Percent of writers to do podcasts together')\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_page = 2\n",
    "curr_author = 'Zach Lowe'\n",
    "curr_pod = 8\n",
    "# for curr_pod in range(0,np.min([9,len(top_podcasts[curr_author][curr_page]['results'])])):\n",
    "curr_info = top_podcasts[curr_author][curr_page]['results'][curr_pod]\n",
    "podcast_keys = curr_info.keys()\n",
    "matches = []\n",
    "for curr_key in podcast_keys:\n",
    "    for j in range(0,len(author_list)):\n",
    "        curr_authorcomp = author_list[j]\n",
    "        search_terms = curr_authorcomp\n",
    "        #     matches = []\n",
    "        if isinstance(curr_info[curr_key], str):\n",
    "#             print(curr_info[curr_key])\n",
    "            last_name = word_tokenize(search_terms)[1]\n",
    "    #         print(last_name)\n",
    "        #     for word in search_terms.split(\" \"):\n",
    "        #         print(word)\n",
    "            if last_name in curr_info[curr_key]:\n",
    "    #                 author_mentions[i,j] = 1\n",
    "                print(curr_authorcomp)\n",
    "                print('woo')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
