{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import re\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "from lxml.html import fromstring\n",
    "from collections import Counter\n",
    "from requests.packages.urllib3.util import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests import Session, exceptions\n",
    "import sys\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from newspaper import Article\n",
    "import json\n",
    "from string import digits\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter \n",
    "from nltk.corpus import wordnet # To get words in dictionary with their parts of speech\n",
    "from nltk.stem import WordNetLemmatizer # lemmatizes word based on it's parts of speech\n",
    "from nltk.corpus import stopwords \n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import cmudict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from langdetect import detect\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "sys.path.append(\"/Users/rohanramesh/Documents/GitHub/Insight_writers/lib/\")\n",
    "from text_processing import ProcessArticle as pa\n",
    "import suggestions as s\n",
    "from scipy.stats import wilcoxon, sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal validations\n",
    "I will use a split article approach to validate my writer style recommendations and my content recommendations. I will compare internal (ie within article) as a control, with random and suggested pairings. I will selected a writer, randomly select an article and split this article in half. I will then select a random writer and a suggested writer, grab an article from each of them, split those articles in half and then calculate the cosine similarity of writing style and content for all pairwise permutations of first and second half of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load from muckrack\n",
    "with open('/Users/rohanramesh/Documents/Insight/data_bball_writers/Attempt3_mr_scrape.pickle', 'rb') as handle:\n",
    "    scrapevar = pickle.load(handle)\n",
    "    \n",
    "# load writer df\n",
    "with open('/Users/rohanramesh/Documents/Insight/data_bball_writers/writer_df.pickle', 'rb') as handle:\n",
    "    writer_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection with database for individual article content\n",
    "client = MongoClient()\n",
    "mydb = client[\"testinsightdb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab information from postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres://rohanramesh@localhost/writer_feature_db\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# establish connection for writer feature db\n",
    "dbname = 'writer_feature_db'\n",
    "username = 'rohanramesh' \n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print(engine.url)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull from database about writer features\n",
    "sql_query = \"\"\"\n",
    "SELECT AVG(\"n_words\") AS \"avg_n_words\",\n",
    "         AVG(\"neg_sent\") AS \"avg_neg_sent\",\n",
    "         AVG(\"neu_sent\") AS \"avg_neu_sent\",\n",
    "         AVG(\"pos_sent\") AS \"avg_pos_sent\",\n",
    "         AVG(\"neg_sent_var\") AS \"avg_neg_sent_var\",\n",
    "         AVG(\"neu_sent_var\") AS \"avg_neu_sent_var\",\n",
    "         AVG(\"pos_sent_var\") AS \"avg_pos_sent_var\",\n",
    "        AVG(\"n_sentences\") AS \"avg_n_sentences\",\n",
    "        AVG(\"n_wordspersentence\") AS \"avg_n_wordspersentence\",\n",
    "        AVG(\"n_wordspersent_variability\") AS \"avg_n_wordspersent_variability\",\n",
    "        AVG(\"wordlength\") AS \"avg_wordlength\",\n",
    "        AVG(\"wordlength_var\") AS \"avg_wordlength_var\",\n",
    "        AVG(\"wordlength_skew\") AS \"avg_wordlength_skew\",\n",
    "        \"author_list\"\n",
    "FROM writer_feature\n",
    "WHERE \"n_words\" > 100\n",
    "GROUP BY \"author_list\"\n",
    "HAVING COUNT(*) > 25 \n",
    "ORDER BY AVG(\"n_words\") DESC\n",
    "\"\"\"\n",
    "writer_feature_subsection = pd.read_sql_query(sql_query,con)\n",
    "writer_feature_subsection.head(10)\n",
    "writer_feature_subsection.replace([np.inf, -np.inf], np.nan)\n",
    "writer_feature_subsection = writer_feature_subsection.dropna(axis=0, how='any')\n",
    "norm_writer_feature_subsection = s.normalize_df(writer_feature_subsection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how dividing article in half vs grabbing random article affects classification based on writer style or content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2vec model keyedvectors to make content based suggestions\n",
    "kv = gensim.models.KeyedVectors.load(\n",
    "    \"/Users/rohanramesh/Documents/Insight/data_bball_writers/word2vec_model_kv.kv\", mmap='r')\n",
    "# load word2vec df for comparisons - this is a collection of the word2vec vectors for all articles in db\n",
    "w2v_df = pd.read_pickle('/Users/rohanramesh/Documents/Insight/data_bball_writers/word2vec_trained.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for calculating cosine similarity between two articles for both writing style and content\n",
    "def compare_content_two_articles(keyedvectors, w2v_df, article1, article2):\n",
    "    \"\"\"\n",
    "    calculate the cos sim between two articles by running both articles through w2v model\n",
    "    and comparing vectors. The articles can be completely unprocessed\n",
    "    :param keyedvectors: vectors from trained w2v model\n",
    "    :param w2v_df: dataframe with all vectors from previous articles\n",
    "    :param article1: first article (unprocessed text)\n",
    "    :param article2: second article (unprocessed text)\n",
    "    :return: sim: cosine similarity between two articles\n",
    "    \"\"\"\n",
    "    lem_art1 = s.lemstr(gensim.utils.simple_preprocess(article1))\n",
    "    lem_art2 = s.lemstr(gensim.utils.simple_preprocess(article2))\n",
    "    article_vector1 = s.get_vector_from_w2v_model(keyedvectors, lem_art1)\n",
    "    article_vector2 = s.get_vector_from_w2v_model(keyedvectors, lem_art2)\n",
    "    sim = cos_sim(article_vector1, article_vector2)\n",
    "    return sim\n",
    "\n",
    "def compare_style_two_articles(article1, article2, writer_feature_subsection):\n",
    "    \"\"\"\n",
    "    calculate the cos sim between two articles for writing style. \n",
    "    The articles can be completely unprocessed\n",
    "    :param article1: first article (unprocessed text)\n",
    "    :param article2: second article (unprocessed text)\n",
    "    :param writer_feature_subsection: pandas df that has the average writing style for all writers in db\n",
    "    :return: sim: cosine similarity between two articles\n",
    "    :return: norm_vec1: the normalized vector for article1\n",
    "    :return: norm_vec2: normalized vector for article2\n",
    "    \"\"\"\n",
    "    curr1 = pa(article1)\n",
    "    vec1 = curr1.build_feature_vector_for_article()\n",
    "    norm_vec1 = s.normalize_vec(vec1, writer_feature_subsection.mean().tolist(),\n",
    "                             writer_feature_subsection.std().tolist())\n",
    "    curr2 = pa(article2)\n",
    "    vec2 = curr2.build_feature_vector_for_article()\n",
    "    norm_vec2 = s.normalize_vec(vec2, writer_feature_subsection.mean().tolist(),\n",
    "                             writer_feature_subsection.std().tolist())\n",
    "    sim = s.cos_sim(norm_vec1, norm_vec2)\n",
    "    return sim, norm_vec1, norm_vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code chunk that will iterate through all writers and for 50x grab a suggested and a random writer's articles and do the writer style and content based comparisons after splitting all articles in half. Note that for now I am not worrying about splitting words in half when I split the article in half because I was struggling to reverse my word tokenization if I split on word number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zachlowe_nba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/insight_new/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "/anaconda3/envs/insight_new/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "/anaconda3/envs/insight_new/lib/python3.6/site-packages/ipykernel_launcher.py:98: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adrian-wojnarowski\n",
      "lee-jenkins\n",
      "howardbeck\n",
      "marc-stein\n",
      "ethan-sherwood-strauss\n",
      "jason-concepcion\n",
      "kevin-arnovitz\n",
      "tom-haberstroh\n",
      "nate-duncan\n",
      "zach-harper\n",
      "brian-windhorst\n",
      "sam_amick\n",
      "david-aldridge\n",
      "ramona-shelburne\n",
      "jpdabrams\n",
      "kevin-pelton\n",
      "marc-j-spears\n",
      "matt-moore\n",
      "shams-charania\n",
      "kevin-p-oconnor\n",
      "chris-haynes\n",
      "dave-mcmenamin\n",
      "shea-serrano\n",
      "ian-begley\n",
      "rachel-nichols\n",
      "ben-golliver\n",
      "mike-prada\n",
      "robmahoney\n",
      "tim-macmahon\n",
      "chris-herring\n",
      "billsimmons\n",
      "jonathan-tjarks\n",
      "amin-elhassen\n",
      "bobby-marks\n",
      "danny-leroux\n",
      "chris-mannix\n",
      "dan-devine\n",
      "michael-pina\n",
      "thompsonscribe\n",
      "ben-golliver\n",
      "ben-falk\n",
      "ian-levy\n",
      "tim-bontemps\n",
      "henry-abbott\n",
      "scott-rafferty\n",
      "ja-dubin\n",
      "michael-lee\n",
      "alex-kennedy\n",
      "derek-bodner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/insight_new/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/envs/insight_new/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom-ziller\n",
      "chris-ballard\n",
      "josh-eberley\n",
      "adi-joseph\n",
      "adam-mares\n",
      "sam-vecenie\n",
      "meet-katie-nolan\n",
      "andrew-sharp\n",
      "david-thorpe\n",
      "royce-webb\n",
      "ericpincus\n",
      "nick-sciria\n",
      "paul-flannery\n",
      "You must `download()` an article first!\n"
     ]
    },
    {
     "ename": "ArticleException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-ec3044567c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0msuggestedmatch_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0msuggestedmatch_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_content_two_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_article\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0msimilarity_within_sugg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuggestedmatch_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Insight_writers/lib/suggestions.py\u001b[0m in \u001b[0;36mgrab_article\u001b[0;34m(article_url)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlem_art\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlem_art\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/insight_new/lib/python3.6/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow_if_not_downloaded_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/insight_new/lib/python3.6/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mthrow_if_not_downloaded_verbose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_STARTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You must `download()` an article first!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArticleException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             print('Article `download()` failed with %s on URL %s' %\n",
      "\u001b[0;31mArticleException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over all relevant authors and do the bootstrap comparison x times\n",
    "# TODO: turn the output of random and suggested writer comparisons into fn bc right now way too repetitive\n",
    "authorlist = norm_writer_feature_subsection['author_list'].tolist()\n",
    "n_articles_test = 50\n",
    "n_articles_comp = 50\n",
    "n_boot_comp = 50\n",
    "n_terms_in_vec = 13\n",
    "similarity_within_author = {}\n",
    "baseline_across_author = {}\n",
    "similarity_within_sugg = {}\n",
    "# iterate over authors\n",
    "for ii in range(0,np.shape(writer_df)[0]):\n",
    "    curr_name = writer_df['website_name'][ii]\n",
    "    curr_name_full = writer_df['Idea Text'][ii]\n",
    "    print(curr_name)\n",
    "    # only continue if there are actual suggestions in out dataset\n",
    "    sugg = s.give_author_suggestion_from_author(writer_feature_subsection, curr_name)\n",
    "    if not isinstance(sugg, pd.DataFrame):\n",
    "        continue\n",
    "    t = time.time()\n",
    "    currcol = mydb[curr_name]\n",
    "    y = currcol.find({\"name\": curr_name})\n",
    "    totalarticlen = y.count()\n",
    "    # require the author to have at least 25 articles otherwise things get funky with sampling 50 times\n",
    "    if totalarticlen < 25:\n",
    "        continue\n",
    "    # preallocate for each comp\n",
    "    similarity_within_author[curr_name] = {}\n",
    "    baseline_across_author[curr_name] = {}\n",
    "    similarity_within_sugg[curr_name] = {}\n",
    "    content_sim = []\n",
    "    style_sim = []\n",
    "    # for pooling across first and second half\n",
    "    first_pool = np.empty((n_boot_comp, n_terms_in_vec)) * np.nan\n",
    "    second_pool = np.empty((n_boot_comp, n_terms_in_vec)) * np.nan\n",
    "    # WITHIN AUTHOR AND WITHIN ARTICLE COMPARISON\n",
    "    for jj in range(0, n_boot_comp):\n",
    "        # randomly grab an article from an author\n",
    "        curr_idx = random.sample(range(0,totalarticlen),1)\n",
    "        curr_article = y[curr_idx[0]]['article']\n",
    "        tokens = word_tokenize(curr_article)\n",
    "        # only continue if more than 250 words in article bc the sentiment variability scores aren't accurate with \n",
    "        # fewer than 4 sentences\n",
    "        if len(tokens) < 250: # if fewer than 250 words don't bother\n",
    "            continue\n",
    "        # split article in half - not worrying right now about cutting words in half\n",
    "        first_half = curr_article[0:int(np.floor(len(curr_article)/2))]\n",
    "        second_half = curr_article[int(np.floor(len(curr_article)/2)):]\n",
    "        # calculate similarity between first and second half for both content and style\n",
    "        content_sim.append(compare_content_two_articles(kv, w2v_df, first_half, second_half))\n",
    "        a, b, c = compare_style_two_articles(first_half, second_half, writer_feature_subsection)\n",
    "        style_sim.append(a)\n",
    "        # now for saving vec\n",
    "        first_pool[jj,:] = b\n",
    "        second_pool[jj,:] = c\n",
    "    similarity_within_author[curr_name]['content'] = content_sim\n",
    "    similarity_within_author[curr_name]['style'] = style_sim  \n",
    "    similarity_within_author[curr_name]['style_avg'] = s.cos_sim(\n",
    "        np.nanmean(first_pool, axis=0), np.nanmean(second_pool, axis=0))    \n",
    "    # now for baseline testing - COMPARE WITH RANDOM WRITER\n",
    "    baseline_style = []\n",
    "    baseline_content = []\n",
    "    baseline_style_avg = []\n",
    "    # pool across baseline first and second halves\n",
    "    first_poolb = np.empty((n_boot_comp, n_terms_in_vec)) * np.nan\n",
    "    second_poolb = np.empty((n_boot_comp, n_terms_in_vec)) * np.nan\n",
    "    # iterate over all randomly selected pairings\n",
    "    for j in range(0,n_boot_comp):\n",
    "        # randomly select a writer, TODO: make this not a suggested writer\n",
    "        new_author = random.sample(writer_df['website_name'].tolist(), 1)[0]\n",
    "        # have to establish new connection to the mongo db for this writer\n",
    "        currcol2 = mydb[new_author]\n",
    "        y2 = currcol2.find({\"name\": new_author}) # this is collection for that writer\n",
    "        totalarticlen = y2.count()\n",
    "        if totalarticlen == 0: # if no articles then continue\n",
    "            continue\n",
    "        # randomly grab an article from this writer\n",
    "        curr_idx = random.sample(range(0,totalarticlen),1)\n",
    "        curr_article2 = y2[curr_idx[0]]['article']\n",
    "        tokens = word_tokenize(curr_article2)\n",
    "        if len(tokens) < 250: # if fewer than 250 words don't bother\n",
    "            continue\n",
    "        # split article control in half - not worrying right now about cutting words in half\n",
    "        first_half_control = curr_article2[0:int(np.floor(len(curr_article2)/2))]\n",
    "        second_half_control = curr_article2[int(np.floor(len(curr_article2)/2)):]\n",
    "        # now do comps for first and second half - with first or second half from original writer\n",
    "        # comparisons are for both content and style\n",
    "        baseline_content.append(compare_content_two_articles(kv, w2v_df, first_half, second_half_control))\n",
    "        a, b, c2 = compare_style_two_articles(first_half, second_half_control, writer_feature_subsection)\n",
    "        baseline_style.append(a)\n",
    "        baseline_content.append(compare_content_two_articles(kv, w2v_df, second_half, first_half_control))\n",
    "        a, b, c1 = compare_style_two_articles(second_half, first_half_control, writer_feature_subsection)\n",
    "        baseline_style.append(a)\n",
    "        # for avg style\n",
    "        first_poolb[j,:] = c1\n",
    "        second_poolb[j,:] = c2\n",
    "    # append information for baseline random comparrison\n",
    "    baseline_across_author[curr_name]['content'] = baseline_content\n",
    "    baseline_across_author[curr_name]['style'] = baseline_style \n",
    "    baseline_across_author[curr_name]['style_avg'] = s.cos_sim(\n",
    "                            np.nanmean(first_pool, axis=0), np.nanmean(second_poolb, axis=0))\n",
    "    # now do same thing but for suggested artists\n",
    "    author_sugg = sugg['authors'].tolist()[0:4] # these are suggested authors\n",
    "    suggestedmatch_style = []\n",
    "    suggestedmatch_style_avg = []\n",
    "    # for pooled\n",
    "    first_pools = np.empty((n_boot_comp, n_terms_in_vec)) * np.nan\n",
    "    second_pools = np.empty((n_boot_comp, n_terms_in_vec)) * np.nan\n",
    "    for j in range(0,n_boot_comp):\n",
    "        # randomly grab a suggested author and access his collection on mongo\n",
    "        new_author = random.sample(author_sugg, 1)[0]\n",
    "        currcol2 = mydb[new_author]\n",
    "        # these are suggested articles\n",
    "        y2 = currcol2.find({\"name\": new_author})\n",
    "        totalarticlen = y2.count()\n",
    "        if totalarticlen == 0: # if no suggested articles continue\n",
    "            continue\n",
    "        # randomly sample selected article\n",
    "        curr_idx = random.sample(range(0,totalarticlen),1)\n",
    "        curr_article2 = y2[curr_idx[0]]['article']\n",
    "        tokens = word_tokenize(curr_article2)\n",
    "        if len(tokens) < 250: # if fewer than 250 words don't bother\n",
    "            continue\n",
    "        # split article control in half - not worrying right now about cutting words in half\n",
    "        first_half_sugg = curr_article2[0:int(np.floor(len(curr_article2)/2))]\n",
    "        second_half_sugg = curr_article2[int(np.floor(len(curr_article2)/2)):]\n",
    "        # now do comps for first and second half for both content and style\n",
    "        a, b, c2 = compare_style_two_articles(first_half, second_half_sugg, writer_feature_subsection)\n",
    "        suggestedmatch_style.append(a)\n",
    "        a, b, c1 = compare_style_two_articles(second_half, first_half_sugg, writer_feature_subsection)\n",
    "        suggestedmatch_style.append(a)\n",
    "        # for avg\n",
    "        first_pools[j,:] = c1\n",
    "        second_pools[j,:] = c2\n",
    "    similarity_within_sugg[curr_name]['style'] = suggestedmatch_style \n",
    "    similarity_within_sugg[curr_name]['style_avg'] = s.cos_sim(\n",
    "                            np.nanmean(first_pool, axis=0), np.nanmean(second_pools, axis=0))\n",
    "    # suggestions based on content of article from articles in db\n",
    "    a = s.lemstr(gensim.utils.simple_preprocess(curr_article))\n",
    "    b = s.recommend_article_content(kv, w2v_df, lem_text=a)\n",
    "    c = b['url'].tolist()[0:5] \n",
    "    suggestedmatch_content = []\n",
    "    for i in c:\n",
    "        m, n = s.grab_article(i)\n",
    "        suggestedmatch_content.append(compare_content_two_articles(kv, w2v_df, curr_article, m.text))\n",
    "    similarity_within_sugg[curr_name]['content'] = suggestedmatch_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paul-flannery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/insight_new/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Pool across all writers to get a sense for what this looks like for writers as a population\n",
    "tmpauthorlist = similarity_within_author.keys()\n",
    "style_sim_within = []\n",
    "style_sim_across = []\n",
    "style_sim_sugg = []\n",
    "content_sim_within = []\n",
    "content_sim_across = []\n",
    "content_sim_sugg = []\n",
    "for ii in similarity_within_author:\n",
    "    try:\n",
    "        content_sim_across.append(np.nanmedian(baseline_across_author[ii]['content']))\n",
    "        content_sim_within.append(np.nanmedian(similarity_within_author[ii]['content']))\n",
    "        content_sim_sugg.append(np.nanmedian(similarity_within_sugg[ii]['content']))\n",
    "        style_sim_across.append(np.nanmedian(baseline_across_author[ii]['style_avg']))\n",
    "        style_sim_within.append(np.nanmedian(similarity_within_author[ii]['style_avg']))\n",
    "        style_sim_sugg.append(np.nanmedian(similarity_within_sugg[ii]['style_avg']))\n",
    "        # also look at actual value\n",
    "#         r = s.give_author_suggestion_from_author(writer_feature_subsection, ii)\n",
    "    except:\n",
    "        print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6529324405048034\n",
      "0.9056892022655406\n",
      "0.8879799181090291\n",
      "0.37714886278881365\n",
      "0.7668313101314218\n",
      "0.6280584054023554\n"
     ]
    }
   ],
   "source": [
    "# These are the values across all writers\n",
    "print(np.nanmean(content_sim_across))\n",
    "print(np.nanmean(content_sim_within))\n",
    "print(np.nanmean(content_sim_sugg))\n",
    "print(np.nanmean(style_sim_across))\n",
    "print(np.nanmean(style_sim_within))\n",
    "print(np.nanmean(style_sim_sugg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save or load variables for figure making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these variables\n",
    "# validation_variables = [similarity_within_author, baseline_across_author, similarity_within_sugg]\n",
    "# with open('/Users/rohanramesh/Documents/Insight/data_bball_writers/validation_variables.pickle', 'wb') as handle:\n",
    "#     pickle.dump(validation_variables, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# for load\n",
    "with open('/Users/rohanramesh/Documents/Insight/data_bball_writers/validation_variables.pickle', 'rb') as handle:\n",
    "    validation_variables = pickle.load(handle)\n",
    "similarity_within_author = validation_variables[0]\n",
    "baseline_across_author = validation_variables[1]\n",
    "similarity_within_sugg = validation_variables[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for style bar plot\n",
    "plt.bar(range(0,3),[np.nanmean(style_sim_within), \n",
    "                    np.nanmean(style_sim_across), \n",
    "                   np.nanmean(style_sim_sugg)], 0.75, \n",
    "        yerr=[sem(style_sim_within), sem(style_sim_across), sem(style_sim_sugg)], \n",
    "        tick_label= ['Within author', 'Random author', 'Suggested author'])\n",
    "plt.ylabel('Style similarity')\n",
    "plt.ylim([0, 1])\n",
    "plt.savefig('/Users/rohanramesh/Documents/Insight/Presentation_material/Figures/Style_similarity.eps', format='eps', dpi=1000)\n",
    "plt.show()\n",
    "# for content bar plot\n",
    "plt.bar(range(0,3),[np.nanmean(content_sim_within), \n",
    "                    np.nanmean(content_sim_across), \n",
    "                   np.nanmean(content_sim_sugg)], 0.75, \n",
    "        yerr=[sem(content_sim_within, nan_policy='omit'),\n",
    "              sem(content_sim_across, nan_policy='omit'), sem(content_sim_sugg, nan_policy='omit')], \n",
    "        tick_label= ['Within article', 'Random article', 'Suggested article'])\n",
    "plt.ylabel('Content similarity')\n",
    "plt.ylim([0, 1])\n",
    "plt.savefig('/Users/rohanramesh/Documents/Insight/Presentation_material/Figures/Content_similarity.eps', format='eps', dpi=1000)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
